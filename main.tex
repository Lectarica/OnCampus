\documentclass[12pt]{jreport}
\usepackage{comment}
\usepackage{fullpage}
\usepackage{float}
\usepackage{color}
\usepackage{multicol}
\usepackage[dvipdfmx]{pict2e}
\usepackage{wrapfig}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{bm}
\usepackage{url}
\usepackage{underscore}
\usepackage{colortbl}
\usepackage{subfigure}
\usepackage{tabularx}
\usepackage{fancyhdr}
\usepackage{ulem}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{hyperref}
\usepackage{algorithmic}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[ipaex]{pxchfon}

\lstdefinestyle{cppbook}{
  language=C++,
  basicstyle=\ttfamily\small,
  numbers=left,
  numberstyle=\scriptsize,
  stepnumber=1,
  numbersep=8pt,
  frame=single,
  framerule=0.3pt,
  breaklines=true,
  breakatwhitespace=true,
  tabsize=2,
  showstringspaces=false,
  columns=fullflexible,
  keepspaces=true,
  captionpos=b
}


\begin{document}

\title{C++による数値計算}
\author{志村昂輝}
\maketitle

一級品として表れる諸々の技術や芸当は、その自由自在さで我々を驚かせますが、その背後には素人の知りえない膨大なルールと型があります。研究も例外ではなく、よりよい研究で発揮される個性はまずある一定の型やルールを身に着けた後に生まれています。研究における型を身に着ける最初の手段は、例えば学部生のうちには標準的な教科書を読んで知識を増やすことでしょうが、これは全くもって序の口にすぎず、一人前となるためには配属された研究室で師弟関係を結び、その研究室が売りとするスタイルを吸収していかなければなりません。

問題となるのが、この研究室の売りは一朝一夕に掴めるものではないということです。まず師弟関係の下で、弟子として師匠の謦咳に接しているかどうかが、素人とそうでない人とを分ける最初の分水嶺となります。将来自分の同業者になると見込んだ人間に対して、師匠はその分野の共通言語や常識を叩き込みますが、一人前とみなされるにはその量と厳しさをもってしても数年を要します。修士と博士合わせて5年かかるのは、この修行が並大抵のものではなく、素人から業界人へと決定的に変化させる重大なプロセスであることを示唆しているでしょう。

本稿は以上2つの困難を克服するために作成されています。つまり、加藤研内部で共有されている重要だがインアクセシブルな技術をまとめ、研究を始める際に典型的に出くわす困難とその対処法を示すこと、及び内容を極力端的に整理し、一学生から研究者になるための経路を効率よく整備することです。ただし、私の特殊なバックグラウンドに起因する限界について読者にお断りしなくてはなりません。まず加藤雄介研究室で扱われるテーマと技術は広く、私がここで示す内容はそのほんの一部にすぎないことです。もとより本研究室の強みは数値計算よりも微分方程式の求解や特殊関数の操作といった解析計算に存在しており、本稿の内容はむしろ傍流といえるかもしれません。主流といえるそちらの技術については、読者の皆様が教員との長い議論や共同研究の中で少しずつ身に着けたり、あるいは今後誰かが同様にドキュメント化してくれることを期待いたします。

第1章では、数値計算や解析の作業に適したプログラミング言語の紹介と簡単な文法の解説、及び環境構築の仕方について述べます。

強相関物質の研究スタイルにはかなり決まった型が存在していますが、出発点として死活的に重要なのがハミルトニアンの構築とその対角化です。第2章では、強束縛模型について軽く説明した後、ハミルトニアンを実装する方法、及びその対角化の方法について述べます。ハミルトニアンの対角化により得られた固有値がエネルギー分散ですが、実際に研究したり論文を書いたりするうえで必要なバンド図やフェルミ面の書き方についてもここで解説します。

第3章ではグリーン関数の実装方法について述べます。グリーン関数の虚部から得られる状態密度の描画方法もここで述べます。

\chapter{プログラミング言語の選択と環境構築}
\section{数値計算向きの言語(C++, Fortran)}
数値計算という目的に絞ってもプログラミング言語の選択肢は多岐にわたりますが、物性物理で格子模型や多体問題を扱う場合、計算量は系の大きさや自由度の増加とともに急激に増大します。したがって、実行速度やメモリ配置を意識する必要があり、C++やFortranはそれにふさわしい選択肢の一つとして挙げられます。明示的に型が指定されるために、数値誤差のふるまいを把握しやすくなるのも重要です。

\subsection{C++について}
C++はC言語が基盤となっていますが、クラスやテンプレートといった機能を導入することで大規模なプログラムの構築や保守に向いています。本稿で主に用いる言語です。コンパイラもフリーで手に入り、特にLinuxでは標準装備されています。Windowsでもコンパイラがフリーで入手できるようです。

数値計算上一番大きなメリットはなんといっても、実行速度の速さです。C++はコンパイル型言語で、ループなどが機械語に近い形で最適化されるために、行列演算や反復計算で高い性能を発揮します。また配列の確保や解放を動的に行えば巨大配列を扱うこともできるので、波数空間上の物理量の情報を格納する場合に非常に効率がよいです。数値計算のライブラリも充実しています。

デメリットとして、メモリ管理を意識した低水準な記述が前提となっているために、数値計算にバグが混じりやすくなることが挙げられます。Fortranに比べると覚える概念が多く、特にポインタは大部分の学習者が躓く場所として悪名高いもので、言語に対する正確な理解と注意深い実装が求められます。それでも私がここでC++をお勧めするのは、学習コストが高い分ほかの言語を学習する際のハードルが下がるであろうことや、Fortranに比べるとできることが多いこと、最後に身も蓋もありませんが、筆者がFortranよりも長く触れているためにドキュメントを作りやすいことがあります。例えば個人的に文字列操作はFortranよりもC++のほうが便利だと考えています。

\subsection{Fortranについて}
数値計算の言語としてはFortranも依然重要な選択肢といえます。物性理論だけでなく、科学技術計算に特化した言語として長い歴史を持つために、研究室によっては保守性の観点からFortranによるコーディングを強いる場合もあります。これはオリジナリティ保護の観点から理にかなっていて、研究室の強みがFortranに支えられており、いわば研究室独自のライブラリとして使いまわすことができるのです。大規模プロジェクトならなおさら、既存の技術的な資産を一人で書き換えることも不可能でしょう。しかしながら加藤雄介研究室は数値計算の研究室ではなく、そのような蓄積はないので絶対にFortranを使わなければいけない環境ではありません。

Fortranにはポインタなどの概念が存在せず、比較的コーディングしやすいのも利点です。数値計算以外には基本的に向いていないのがデメリットで、FortranができるよりもC++ができる人のほうが、今後数値計算以外のことを仕事にする場合に融通が利くのではないかと考えています。


\subsection{Python3について}
実のところ筆者が一番長く触れている言語です。数値計算を補助する言語としてPython3も非常に有用です。C++やFortranに比べると、Python3はライブラリが充実していて、可視化やデータ解析を迅速に行える利点もあります。
\footnote[1]{
可視化にはmatplotlib, 数値計算やデータ解析にはnumpyやscipyといったライブラリが便利でしばしば使われます。
}
型指定もないので、簡単な計算を行いたいだけならC++やFortranよりも圧倒的に便利です。特に配列(リスト)の定義が楽で、線形代数関連のライブラリが充実しており簡単に計算できるのは大きな魅力です。コードの読解も比較的やさしく、精神的な負担が少ないです。

Python3はスクリプト言語であり、実行速度やメモリ制御の面ではコンパイル型言語に劣るために、大規模数値計算の中核を担うのには不適切である場合もあります\footnote[2]{厳密には計算効率を上げるための工夫が様々に存在するようですが、その工夫に割くコストを考えると最初からC++やFortranで実装した方がよいという意見が専門家の間では散見されます。}。また型宣言がないのは実装や保守性の観点から苦しみの種となる場合もあります。しかしながら、C++やFortranで実行した本計算の出力をPythonで読み込み、プロットや解析を行うといった使い方は広く行われており、その自由度はほかの言語の追随を許しません。

\subsection{近年注目されている言語(Julia)}
筆者は常用しておらず、軽く触れる程度しかできませんが、近年数値計算を目的としたプログラミング言語として注目されているものの一つにJuliaがあります。素早く実装することができ、かつ可読性が高い部分はPythonに似ていますが、型安定なコードならCやFortranに劣らない速度で計算できるため、両者のいいとこどりをしています。現時点でのデメリットといえば、比較的新しい言語であるためにライブラリやパッケージの進化が早くバージョン管理が大変であろうことだと考えられますが、最近は研究会なども開かれており今後利用者は増えていくと見込まれます。


\section{C++で使える高速数値計算ライブラリ}
行列の積は添え字をループで回して和を取れば計算できますし、フーリエ変換もただの数値積分として実装することは一応できます。しかしそれらを自前で実装するのは時間がかかりますし、何より思わぬバグを招いてなかなか研究が進まないといった問題に直面しえます\footnote[2]{勉強のために一から実装するのは効果的ではありますが、修士博士を途中まで経た身からすると、そうしたことにかまけている時間はそれほどなくお勧めできません}。物性理論で頻出するこうした計算は、標準的なライブラリを呼び出して使うのが一般的です。代表的なものを以下に列挙しますが、実装例はのちの章で軽い文法とともに解説します。
\subsection{BLAS/LAPACK(線形代数用ライブラリ)}
BLASはベクトルおよび行列に対する基本的な演算を提供する数値線形代数のライブラリで、ベクトルの内積をはじめ行列とベクトルの積、行列と行列の積も計算することが出来ます。これらの演算はそれぞれLevel 1, 2, 3のように分類されています。LAPACKはBLASを基礎として、行列の対角化や連立一次方程式の求解などを行うことができます。LU分解やQR分解などの行列の分解を行うこともできます。これらの外部ライブラリは時と試行回数の試練を潜り抜け、正確性を保証した業界のデファクトスタンダードとなっています。
\subsection{FFTW3(フーリエ変換)}
高速フーリエ変換(FFT)は読んで字のごとく、フーリエ変換を高速に行うためのライブラリです。多次元のフーリエ変換も行うことが出来ます\footnote[1]{昔はメッシュサイズが2の冪でないと計算できなかったようですが、アルゴリズムの進歩により任意のメッシュサイズで計算できるようになっています。}。関数にはいろいろあり、実数関数と複素関数で使い分ける必要があります。また逆フーリエ変換とフーリエ変換の係数の違いは反映していないので、こちらで指定する必要があります。
\subsection{OpenMP(並列計算)}
ループ計算を行うとき、メモリ並列を行って複数の計算を同時に行うことで時間が短縮できることがあります。その手段としてOpenMPが用いられます。並列化にはMPIという手段もありますが、MPIはプロセスごとに情報の通信を行う必要があり、やや学習コストが高いものとなっています。スレッド並列なので既存のコードをほとんど変えずに並列化可能なのが利点とも言えます。

\chapter{C++による数値計算の基礎}

\section{C++の文法速習}

\section{C++による対角化}
本節では、C++からLAPACKを呼び出してエルミート行列を対角化するための手順をまとめます。複素行列を扱うか実対称行列を扱うかで用いるLAPACKのルーチンが異なる点にも注意すべきですが、呼び出し自体は数行で済みます。
対角化には、エルミート行列を対角化するzheevか、dsyevを用います。LAPACKはもともとFortranで用いられていたライブラリであるため、column-majorでメモリの連続領域に格納されています。そこでC++ではs\texttt{td::vector<std::complex<double>>}を用いることで、要素$H_{ij}$に$H[i + N*j]$としてアクセスすることにします。

サンプルプログラムは\textbf{chapter2-1.cpp}です。

\subsection{zheevの引数}
zheevの引数はこちらが考えて指定するものはそれほど多くなく、慣れれば簡単に実装できるようになりますが、一応各引数の説明をします。
\begin{itemize}
  \item \texttt{jobz} : char型。'V'か'N'の値をとる。'V'では固有値と固有ベクトルを計算する。'N'では固有値のみを計算する。
  \item \texttt{uplo} : char型。'U'か'L'の値を取る。エルミート行列は上三角部分と下三角部分さえ参照すれば全体の情報が分かるので、どちらの部分を参照するかを指定する。
  \item \texttt{n} : int型。対角化する行列のサイズを入力する。$3 \times 3$行列なら3と入力する。
  \item \texttt{a(n*n)} : \texttt{std::vector<std::complex<double>>}型。入力として、対角化したい行列を与える。
  \item \texttt{lda} : int型。普通はnでよい。これは1次元配列として行列を考えたときに、次の列の情報をメモリのどこに渡すかを指定するものなので、nより大きな値を指定しても動く場合が多い。むしろnより小さな値を与えると意図しない結果をもたらすことになる。
  \item \texttt{w} : \texttt{std::vector<double>}型。行列の固有値を昇順に返す。エルミート行列の固有値はすべて実数であるので、double型としてよい。
  \item \texttt{lwork} : int型で、最初に-1を指定する。対角化しようとしている行列サイズで作業配列がどれくらい必要かをLAPACKに問い合わせるための引数。
  \item \texttt{work} : \texttt{std::complex<double>*}型。lworkで取得したサイズでworkを確保する。
  \item \texttt{rwork} : \texttt{std::vector<double>}型。ふつうは\texttt{3*n-2}で指定する。
  \item \texttt{info} : int型。対角化の一連の作業が正常終了したかどうかを表し、例外処理などに用いる。infoが0なら正常終了しているが、それ以外の場合はどこかで失敗している。infoが正の値であると、$-\mathrm{info}$番目の引数に不正があったことが示される。infoが正の場合は固有値計算が収束しなかったことを示す。
\end{itemize}
zheevは入力で与えた行列を上書きするので、元のハミルトニアンを別に使いたい場合は、対角化前に行列をコピーして保持しておくべきです。

\subsection{コンパイルおよび実行}
LAPACKは単体では動かず、内部でBLASも呼び出しています。したがって、C++でLAPACKを使う場合、リンク時にLAPACKとBLASを同時にリンクする必要があります。コンパイルは
\begin{lstlisting}
  g++ chapter2-1.cpp -O2 -llapack -lblas -o main
\end{lstlisting}
のように行います。無事コンパイルが終わると実行ファイル\texttt{main}が生成されるので、
\begin{lstlisting}
  ./main
\end{lstlisting}
で実行できます。

\subsection{対角化の手順}
chapter2-1.cppは、$3\times3$のエルミート行列
\begin{equation}
  H =
\begin{pmatrix}
1.0 & 0.2 + 0.1 i & 0 \\
0.2 - 0.1 i & 2.0 & 0.3 \\
0 & 0.3 & 3.0
\end{pmatrix}
\end{equation}
を対角化し、行列の固有値と固有ベクトルを出力するコードです。また対角化が出来ているかどうかの検証も行っています。

LAPACKの関数をC++から呼ぶために、\texttt{extern "C"}という宣言を行っています。もともと\texttt{dsyev}と\texttt{zheev}はFortranで実装されている関数で、C++から呼び出すのために必要な宣言となっています。\footnote[1]{C++ではname manglingといい、関数の名前を定めるときに、引数の型や返却値の型など複数の意味を含めて修飾する手法があります。C++で参照する名前とFortranで参照する名前が違う場合に、\texttt{extern "C"}とすることでC言語と互換な名前解決を試みることが出来ます。}

またここでは行列を表現する配列を実装する際に\texttt{template <class T>}を使うことで、\texttt{T}を型パラメータとして、Tがdouble型であっても、複素型であっても同じ行列として認識できるようにしています。


では実際にプログラムを実行してみましょう。この行列の固有値は
\begin{equation*}
  \lambda_1 \approx 0.95028847,\qquad
\lambda_2 \approx 1.96487426,\qquad
\lambda_3 \approx 3.08483726 .
\end{equation*}
となっていて、解析的にはきれいに求まりません。きちんと対角化できているかをチェックするには、エルミート行列の固有値及び固有ベクトルの性質に問題がないかを確かめる必要がありますが、ここではエルミート行列の以下のような性質を用いて検証します。
\begin{itemize}
  \item 固有値は実数である
  \item 固有ベクトルは正規直交系をなす
\end{itemize}

上の2つの性質から、固有ベクトルを並べた行列$V$が$V^{\dagger}V = \mathcal{I}$を満たすことがわかります。

chapter2-1.cppを実行すると、出力結果は以下のようになります。
\begin{lstlisting}
Eigenvalues (ascending):
  w[0] = 0.950288
  w[1] = 1.96487
  w[2] = 3.08484

Eigenvectors (columns):
v[0] = ( (-0.872671,-0.436335) (0.216909,0) (-0.0317472,0) )
v[1] = ( (-0.194332,-0.0971661) (-0.937531,0) (0.271715,0) )
v[2] = ( (0.0260935,0.0130468) (0.272004,0) (0.961854,0) )

Max residual norm2: 4.44957e-16
\end{lstlisting}
要素数3の1次元配列$w$に固有値が昇順に格納されています。また規格化された固有ベクトルが1次元配列vに格納されています。Max residual norm2は、各固有値$\lambda_i$と対応する固有ベクトル$\mathbf{v}_i$について$r_i = |\hat{H}\mathbf{v} - \lambda_i \mathbf{v}_i|^2$を計算し、その最大値として与えています。最大値が$10^{-16}$程度なので、数値誤差の程度で一致しており、対角化の結果が正しいことが保証されています。

\section{C++によるFFTW3を用いたフーリエ変換}
次にFFTWを用いたフーリエ変換の解説に移ります。FFTWは高速フーリエ変換を行うためのライブラリです。大まかにはまず\texttt{fftw_plan_*}のように用意されている関数でplanを作成し、\texttt{fftw_execute(plan)}でplanを実行する、という流れになります。フーリエ変換後にplanとメモリを開放することを忘れないようにしてください。

ところでFFTWを用いる際は、通常では見慣れない型がいくつか登場します。まずFFTWにおける複素数型は
\begin{lstlisting}
  typedef double fftw_complex[2];
\end{lstlisting}
のように定められています。\texttt{[0]}には実部が、\texttt{[1]}には虚部が対応しています。FFTWで扱う引数は、\texttt{std::complex<double>}を受け付けないので、FFTの際は複素数型に必ずfftw_complexを指定しましょう。

次に、FFTWで要となる\texttt{fftw_plan}型についてです。この型の中身はユーザーからは見えないのですが、入力値や次元数、最適化の仕方やアルゴリズムなどが内部に保持されています。我々の行うことは、フーリエ変換のためのplanを作成し、それを\texttt{fftw_plan}で実行することです。

FFTWは扱うデータ型に応じて関数名が分かれています。
\begin{itemize}
  \item fftw_complex 型から fftw_complex 型への変換: 複素関数から複素関数の変換に対応し、\texttt{fftw_plan_dft_*}と名前が付いた関数を使う。\footnote[1]{筆者はこれしか使ったことがありません。}
  \item double 型から double 型 への変換 : 実関数から実関数への変換に対応し、\texttt{fftw_plan_dft_r2c_*}と名前がついた関数を用いる。
  \item double 型から fftw_complex 型への変換 : 実関数から複素関数への変換に対応し、\texttt{fftw_plan_dft_c2r_*}と名前の付いた関数を用いる。
  \item fftw_complex 型から double 型への変換 : 複素関数から実関数への変換に対応し、\texttt{fftw_plan_dft_r2r_*}と名前の付いた関数を用いる。
\end{itemize}
他にも、関数名の先頭を\texttt{fftwf_}としてfloat型を扱う関数や、関数名の先頭を\texttt{fftwl_}としてlong double型を扱う関数が存在します。


\subsection{fftw_plan fftw_plan_dft_2dの引数}
\begin{itemize}
  \item \texttt{n0} : int型。第1次元の格子点の数。
  \item \texttt{n1} : int型。第2次元の格子点の数。
  \item \texttt{in} : fftw_complex*型。入力となる複素数配列を示す。実部と虚部を切り分ける必要があり、ある数aに対して\texttt{in[ix * n1 + iy][0] = a.real(); in[ix * n1 + iy][1] = a.imag();}を指定しなければならない。
  \item \texttt{out} : fftw_complex*型。出力用の複素数配列。入力の配列が破壊されてしまうことを許容すれば\texttt{in == out}としてもよい。
  \item \texttt{sign} : int型。指定可能な値は\texttt{FFTW_FORWARD}か\texttt{FFTW_BACKWARD}の2つである。それぞれ順変換と逆変換に対応する。逆変換後には正規化を行うべし。
  \item \texttt{flags} : unsigned型。\texttt{FFTW_ESTIMATE}と\texttt{FFTW_MEASURE}の2つがある。
\end{itemize}

\subsection{フーリエ変換の手順}
ここでは、実空間表示の関数を波数空間の関数にフーリエ変換する関数を作ってみましょう。実空間表示の関数として、ここでは2次元格子上ローレンチアン
\begin{equation}
  f(x,y) = \frac{\delta^2}{x^2+y^2+\delta^2}
\end{equation}
を採用します。2次元フーリエ変換
\begin{equation}
  F(k_x,k_y) = \sum_{x,y} e^{-i(k_x x+ k_y y)} f(x,y)
\end{equation}
をFFTWで数値計算して波数空間上にプロットします。なお上のようなローレンチアンのフーリエ変換は厳密解が知られていて
\begin{equation}
  F(k_x,k_y) = 2\pi\delta^2 K_0(\delta |k|)
\end{equation}
となります。ここで$K_0(x)$は第2種変形ベッセル関数です。

\begin{figure}[t]
  \centering
  \subfigure[(a) Real space]{
    \includegraphics[width=0.45\linewidth]{lorentzianreal.eps}
  }
  \hfill
  \subfigure[(b) k space]{
    \includegraphics[width=0.45\linewidth]{lorentziankmag.eps}
  }
  \caption{Real-space Lorentzian and its Fourier transform.}
    \hfill
  \subfigure[(c) compare exact]{
    \includegraphics[width=0.45\linewidth]{lorentzian-kx-slice-ky0.eps}
  }
  \caption{Real-space Lorentzian and its Fourier transform.}
  \label{fig:lorentzian-fft}
\end{figure}

図\ref{fig:lorentzian-fft}(a)にはフーリエ変換前の実空間のローレンチアンのカラーマップ、(b)にはフーリエ変換後のローレンチアンのカラーマップを示しています。

\section{C++によるOpenMPを用いた並列計算}
OpenMPはメモリ共有によって並列計算を行うためのAPIで、C++やFortranのコードに対して並列化を行うことができます。1つのプロセスの内部で複数のスレッドを生成し、それらが同一のメモリを共有しながら計算を行います。したがって、配列やグローバル変数をそのまま共有して用いることが出来ます。まずparallel regionを作り、その中でタスクをスレッドに分配し、各スレッドが同時に計算を実行する、というのがOpenMPによる並列化のおおまかな流れです。

\subsection{いかなるときに並列化が有効か}
並列化は、ループの反復が互いに独立であるときに適しています。最も頻繁に使われるのは多重積分でしょう。また、パラメータの掃引においても並列化は威力を発揮します。独立であるかを判断する目安として、並列化させる計算の順序を入れ替えても良いかどうかを検討するとよいです。

もちろんすべてのプログラムが並列化可能なわけではありません。例えば、各for文の計算が非常に軽い場合はむしろ並列化のためのオーバーヘッドのほうが負荷になります。また各ループの計算が独立でない場合は意図しない結果をもたらしたり、そもそも並列化不可能であったりします。例えば漸化式のように、i番目の計算を出力するのにi-1番目の結果が必要になる場合は並列化を適用できません。

\subsection{基本的な使い方}
OpenMPはコンパイラが対応している必要がありますが、本稿で主に用いるg++ではデフォルトで使うことが出来ます。使用時はコンパイルオプションに-fopenmpを付ければよく、例えばコンパイル時に
\begin{lstlisting}
  g++ -O2 -fopenmp main.cpp -o main
\end{lstlisting}
とします。

対角化やフーリエ変換と比べると、メモリや操作順序を意識しなければならないという点で並列化には別の困難がありますが、実装自体は大変簡単で、以下の3つの指示を覚えれば基本的には事足ります。
\begin{itemize}
  \item \texttt{parallel / parallel for} : parallelは並列領域を作成する指示。ほとんどfor文と組み合わせて使うのでparallel forと書くことが多い。
  \item \texttt{shared / private} : 変数を各スレッドごとにコピーするか、全てのスレッドで共有されるものかを区別するのに使う指示。
  \item \texttt{reduction} : 複数のスレッドが計算した結果を1つにまとめるために使う。例えば、総和や内積など。
\end{itemize}

スレッド数は実行時に環境変数を指定すれば変更することが出来ます。例えば実行前に
\begin{lstlisting}
export OMP_NUM_THREADS=4
\end{lstlisting}
とすれば、OpenMPは4スレッドで実行されます。

\subsection{\texttt{parallel / parallel for}}
chapter2-3-1.cppをコンパイルし実行してみましょう。正しい挙動を示せば出力は以下のようになるはずです。

\begin{lstlisting}
thread 9 / 16
thread 10 / 16
thread 2 / 16
...
\end{lstlisting}

まず\texttt{\#pragma omp parallel}でparallel regionを作成すると、OpenMPがスレッドを複数作成します。この場合は16本作成されています。\texttt{omp_get_thread_num()}がスレッド番号を、\texttt{omp_get_num_threads()}がparallel regionの中のスレッド数を指しています。つまり\texttt{thread i / 16}は16本あるスレッドのうちi番目のスレッドが標準出力を実行したことになります。

chapter2-3-2.cppをコンパイルし実行すると、出力は以下のようになります。
\begin{lstlisting}
i = 6, thread = 6
i = 0, thread = 0
i = 7, thread = 7
...
\end{lstlisting}
このように各スレッドでバラバラに計算が行われます。

\subsection{OpenMPにおける変数の扱い(\texttt{shared/private})}
OpenMPでは、parallel regionに入ったときに各変数が全てのスレッドで共有されているのか、あるいはスレッドごとに独立に定められるのかを意識する必要があります。例えばすべてのスレッドで統一したかった変数が各スレッドで書き換えられてしまい、実行ごとに値が変わってしまうトラブルが起こり得ますが、こうした問題を防ぐために変数がsharedかprivateかを定めておく必要があります。shared変数は全スレッドが同じメモリ領域を参照するので、1つの変数を全員で共有していると考えることが出来ます。一方でprivateな変数は、各スレッドが専用にコピーを保持し、他のスレッドが参照するのを防ぎます。

簡単な例でその違いを実感してみましょう。chapter2-3-3.cppは、xに1を加算していく操作を並列して行うもので、直観的にはスレッド数が出力されるはずです。しかし結果は実行ごとに異なる値を吐き出します。並列計算では変数をデフォルトでsharedとしており、計算の競合が発生するためです。\footnote[1]{実行結果が毎回異なるのは少々発展的な話題であるので脚注にまとめます(しかし大事です！)。まずxに1を足すという操作(\texttt{x += 1})は、CPUの中で複数の手順を通じて行われます。「メモリからxを読み込み、レジスタ上でインクリメントし、結果をメモリに書き戻す」というのが\texttt{x += 1}で行われていることです。今、スレッド1とスレッド2が同時に\texttt{x += 1}を実行すると、先にスレッド1がメモリから$x = 0$を読み込んだとしても、インクリメントする前にスレッド2がメモリから$x = 0$を読み込んでしまいます(本文で「競合」と呼んだ内容)。すると、スレッド1が$x = 1$をメモリに書き戻した後に再びスレッド2が$x = 1$をメモリに書き込んでしまいます。これにより、スレッド1つ分の操作が消えてしまうことになります。つまり運よく$x$がスレッド数と等しくなることはあるでしょうが、実行のタイムスケジュールは毎回異なるので、多くの場合は$x$は実際のスレッド数より少ない値を吐き出すことになるのです。}

chapter2-3-4.cppではxをprivate変数として保持しています。各スレッドで\texttt{x += 1}し、全てのスレッドで$x = 1$となっていることがお分かりになると思います。

\subsection{reduction}
OpenMPにおけるshared変数の扱いを見ると、並列計算には慎重な取り扱いが必要であることが分かります。例えばfor文を使って配列aと配列bの内積をとる操作においても、脚注で示したような競合が発生し、正しく総和が取られない可能性があります。そこで導入されるのが\texttt{reduction}です。

reductionは各スレッドにprivateな変数を用意して、その変数を更新します。並列領域がクローズした後に、各スレッドで更新済みの変数を合計します。これにより競合をさけ、予期しない挙動を防ぎます。

reductionの基本的な構文は\texttt{\#pragma omp parallel for reduction(operator : variable)}で与えられます。例えば、変数Xに何かの総和を記録するときは、\texttt{\#pragma omp parallel for reduction(+ : X)}とします。

\begin{thebibliography}{9}
  \bibitem{hofstadter} Hofstadter, Douglas R., Energy levels and wave functions of Bloch electrons in rational and irrational magnetic fields, Phys. Rev. B $\bm{14}$, 2239(1976).
  \bibitem{super} C R Dean 1, L Wang, P Maher, C Forsythe, F Ghahari, Y Gao, J Katoch, M Ishigami, P Moon, M Koshino, T Taniguchi, K Watanabe, K L Shepard, J Hone, P Kim, Hofstadter's butterfly and the fractal quantum Hall effect in moiré superlattices, Nature 497(7451), (2013)
\end{thebibliography}


\end{document}